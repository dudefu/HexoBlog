---
title: spark2.4.2编译（mac系统下）
date: 2019-05-01 23:03:21
categories: 大数据
tags: Spark 
---
## 下载所需要的软件（注意版本）
· Spark-2.4.2.tgz 
· Hadoop-2.7.6 
· Scala-2.11.12
· jdk1.8.0_191
· apache-maven-3.6.x
· git
注意：其中spark是源码，其他是可运行包
## 解压安装并配置环境变量（过程略）
配置完，注意测试。其中，maven配置本地库，镜像地址设置为阿里云地址。
```shell
# 创建本地仓库文件夹
mkdir ~/maven_repo
# 修改settings.xml文件
vim $MAVEN_HOME/conf/settings.xml
```
部分代码：
```xml
<!-- localRepository
   | The path to the local repository maven will use to store artifacts.
   |
   | Default: ${user.home}/.m2/repository
  <localRepository>/path/to/local/repo</localRepository>
  -->
<localRepository>/home/max/maven_repo</localRepository>

<mirrors>
    <mirror>
    <id>nexus-aliyun</id>
    <mirrorOf>*,!cloudera</mirrorOf>
    <name>Nexus aliyun</name>                     
    <url>
      http://maven.aliyun.com/nexus/content/groups/public
    </url>
</mirror>
```
## 修改脚本make-distribution.sh
编译不使用mvn这个命令,直接用make-distribution.sh脚本，但是需要修改该脚本
```shell
#spark-2.4.2文件夹下
vim ./dev/make-distribution.sh

#将这些行注释掉    此处为最佳实践，为的是通过指定版本号减少编译时间
#VERSION=$("$MVN" help:evaluate -Dexpression=project.version $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | grep -v "WARNING"\
#    | tail -n 1)
#SCALA_VERSION=$("$MVN" help:evaluate -Dexpression=scala.binary.version $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | grep -v "WARNING"\
#    | tail -n 1)
#SPARK_HADOOP_VERSION=$("$MVN" help:evaluate -Dexpression=hadoop.version $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | grep -v "WARNING"\
#    | tail -n 1)
#SPARK_HIVE=$("$MVN" help:evaluate -Dexpression=project.activeProfiles -pl sql/hive $@ 2>/dev/null\
#    | grep -v "INFO"\
#    | grep -v "WARNING"\
#    | fgrep --count "<id>hive</id>";\
#    # Reset exit status to 0, otherwise the script stops here if the last grep finds nothing\
#    # because we use "set -o pipefail"
#    echo -n)

##添加一下参数，注意，版本号要对应自己想要的生产环境
VERSION=2.4.2
SCALA_VERSION=2.11
SPARK_HADOOP_VERSION=hadoop-2.6.0-cdh5.14.0
SPARK_HIVE=1
```
## 修改源码包spark-2.4.2下的pom.xml
```xml
<repositories>
    <!--<repositories>
     This should be at top, it makes maven try the central repo first and then others
and hence faster dep resolution
    <repository>
        <id>central</id>
        <name>Maven Repository</name>
        <url>https://repo.maven.apache.org/maven2</url>
        <releases>
            <enabled>true</enabled>
        </releases>
        <snapshots>
            <enabled>false</enabled>
        </snapshots>
    </repository>
-->
    <repository>
        <id>central</id>
        <url>http://maven.aliyun.com/nexus/content/groups/public//</url>
        <releases>
            <enabled>true</enabled>
        </releases>
        <snapshots>
            <enabled>true</enabled>
            <updatePolicy>always</updatePolicy>
            <checksumPolicy>fail</checksumPolicy>
        </snapshots>
    </repository>
    <repository>
        <id>cloudera</id>
        <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
    </repository>
</repositories>
```
## 开始编译
```shell
./dev/make-distribution.sh \
--name hadoop-2.6.0-cdh5.14.0  \
--tgz \
-Phadoop-2.6 \
-Dhadoop.version=2.6.0-cdh5.14.0 \
-Phive -Phive-thriftserver  \
-Pyarn \
-Pkubernetes
```
编译大概需要半小时以上，耐心等待就行。编译过程中如果报错，一般有error字样。
出现以下字样，代表编译完成：
```shell
+ for f in '"$DISTDIR"/examples/jars/*'
++ basename /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/jars/paranamer-2.8.jar
+ name=paranamer-2.8.jar
+ '[' -f /Users/dudefu/BuildSark/spark-2.4.2/dist/jars/paranamer-2.8.jar ']'
+ rm /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/jars/paranamer-2.8.jar
+ for f in '"$DISTDIR"/examples/jars/*'
++ basename /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/jars/scopt_2.11-3.7.0.jar
+ name=scopt_2.11-3.7.0.jar
+ '[' -f /Users/dudefu/BuildSark/spark-2.4.2/dist/jars/scopt_2.11-3.7.0.jar ']'
+ for f in '"$DISTDIR"/examples/jars/*'
++ basename /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/jars/spark-examples_2.11-2.4.2.jar
+ name=spark-examples_2.11-2.4.2.jar
+ '[' -f /Users/dudefu/BuildSark/spark-2.4.2/dist/jars/spark-examples_2.11-2.4.2.jar ']'
+ mkdir -p /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/src/main
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/examples/src/main /Users/dudefu/BuildSark/spark-2.4.2/dist/examples/src/
+ '[' -e /Users/dudefu/BuildSark/spark-2.4.2/LICENSE-binary ']'
+ echo 'Skipping copying LICENSE files'
Skipping copying LICENSE files
+ '[' -e /Users/dudefu/BuildSark/spark-2.4.2/CHANGES.txt ']'
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/data /Users/dudefu/BuildSark/spark-2.4.2/dist
+ '[' false == true ']'
+ echo 'Skipping building python distribution package'
Skipping building python distribution package
+ '[' false == true ']'
+ echo 'Skipping building R source package'
Skipping building R source package
+ mkdir /Users/dudefu/BuildSark/spark-2.4.2/dist/conf
+ cp /Users/dudefu/BuildSark/spark-2.4.2/conf/docker.properties.template /Users/dudefu/BuildSark/spark-2.4.2/conf/fairscheduler.xml.template /Users/dudefu/BuildSark/spark-2.4.2/conf/log4j.properties.template /Users/dudefu/BuildSark/spark-2.4.2/conf/metrics.properties.template /Users/dudefu/BuildSark/spark-2.4.2/conf/slaves.template /Users/dudefu/BuildSark/spark-2.4.2/conf/spark-defaults.conf.template /Users/dudefu/BuildSark/spark-2.4.2/conf/spark-env.sh.template /Users/dudefu/BuildSark/spark-2.4.2/dist/conf
+ cp /Users/dudefu/BuildSark/spark-2.4.2/README.md /Users/dudefu/BuildSark/spark-2.4.2/dist
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/bin /Users/dudefu/BuildSark/spark-2.4.2/dist
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/python /Users/dudefu/BuildSark/spark-2.4.2/dist
+ '[' false == true ']'
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/sbin /Users/dudefu/BuildSark/spark-2.4.2/dist
+ '[' -d /Users/dudefu/BuildSark/spark-2.4.2/R/lib/SparkR ']'
+ '[' true == true ']'
+ TARDIR_NAME=spark-2.4.2-bin-hadoop-2.7.6
+ TARDIR=/Users/dudefu/BuildSark/spark-2.4.2/spark-2.4.2-bin-hadoop-2.7.6
+ rm -rf /Users/dudefu/BuildSark/spark-2.4.2/spark-2.4.2-bin-hadoop-2.7.6
+ cp -r /Users/dudefu/BuildSark/spark-2.4.2/dist /Users/dudefu/BuildSark/spark-2.4.2/spark-2.4.2-bin-hadoop-2.7.6
+ tar czf spark-2.4.2-bin-hadoop-2.7.6.tgz -C /Users/dudefu/BuildSark/spark-2.4.2 spark-2.4.2-bin-hadoop-2.7.6
+ rm -rf /Users/dudefu/BuildSark/spark-2.4.2/spark-2.4.2-bin-hadoop-2.7.6
```
```shell
~/BuildSark/spark-2.4.2  ls
CONTRIBUTING.md                  common                           graphx                           repl
LICENSE                          conf                             hadoop-cloud                     resource-managers
NOTICE                           core                             launcher                         sbin
R                                data                             licenses                         scalastyle-config.xml
README.md                        dev                              mllib                            spark-2.4.2-bin-hadoop-2.7.6.tgz
appveyor.yml                     dist                             mllib-local                      sql
assembly                         docs                             pom.xml                          streaming
bin                              examples                         project                          target
build                            external                         python                           tools
```

